{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# DeBussy (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install torch-summary\n",
        "\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX module...')\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDIX\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "from GPT2RGAX import *\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "import pretty_midi\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ALL-Piano Dataset\n",
        "!wget --no-check-certificate -O 'ALL-Piano.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118569&authkey=AAYVqXUlxXmpFqk\"\n",
        "!unzip ALL-Piano.zip"
      ],
      "metadata": {
        "id": "z5E8HXOJX-xZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GiantMIDI Dataset\n",
        "!wget --no-check-certificate -O 'GiantMIDI.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118494&authkey=AJr3wBuauBiEzVQ\"\n",
        "!unzip GiantMIDI.zip"
      ],
      "metadata": {
        "id": "oRUyw_-HOPuZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Process MIDIs)"
      ],
      "metadata": {
        "id": "PDef3vLcgeYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "ed07b44f-07fe-45fb-a64f-adba8df1bdcb",
          "kernelId": ""
        },
        "id": "on7sgKEP3Yc8"
      },
      "outputs": [],
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI Processor\n",
        "full_path_to_MIDI_dataset_directory = \"/content/ALL-Piano/\" #@param {type:\"string\"}\n",
        "sorted_or_random_file_loading_order = False #@param {type:\"boolean\"}\n",
        "dataset_ratio = 1 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "full_path_to_save_processed_MIDIs = \"/content/DeBussy_Processed_MIDIs\" #@param {type:\"string\"}\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "nocs = []\n",
        "times = []\n",
        "durs = []\n",
        "pitches = []\n",
        "\n",
        "wk = [0, 2, 4, 5, 7, 9, 11] # White Notes\n",
        "bk = [1, 3, 6, 8, 10] # Black Notes\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = full_path_to_MIDI_dataset_directory\n",
        "\n",
        "filez = list()\n",
        "\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        files_count += 1\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix1 = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' and event[3] != 9:\n",
        "                    events_matrix1.append(event)\n",
        "            itrack += 1\n",
        "    \n",
        "        # final processing...\n",
        "\n",
        "        if len(events_matrix1) > 0:\n",
        "\n",
        "            # recalculating timings\n",
        "        \n",
        "            for e in events_matrix1:\n",
        "                # e[1] = int(e[1] / 2) # Time-shift\n",
        "                e[2] = int(e[2] / 2) # Duration\n",
        "\n",
        "            events_matrix1.sort(key=lambda x: x[4], reverse=True) # Sort by pitch H -> L\n",
        "            events_matrix1.sort(key=lambda x: x[1]) # Then sort by start-times\n",
        "            \n",
        "            noc = 254 # Note or Chord (noc)\n",
        "            color = 0 # Note color (ptc+0 or ptc+128)\n",
        "\n",
        "            melody_chords = []\n",
        "\n",
        "            pe = events_matrix1[0]\n",
        "            \n",
        "            for i in range(len(events_matrix1)-1):\n",
        "\n",
        "                time = max(0, min(253, events_matrix1[i][1]-pe[1])) # Time-shift\n",
        "                dur = max(0, min(253, events_matrix1[i][2])) # Duration\n",
        "                ptc = max(0, min(127, events_matrix1[i][4])) # Pitch\n",
        "\n",
        "                if events_matrix1[i][1] > pe[1] and events_matrix1[i+1][1] != events_matrix1[i][1]:\n",
        "                  # noc = 254 # Single Note\n",
        "                  # ptc+0 - White Note\n",
        "                  # ptc+128 - Black Note\n",
        "\n",
        "                  noc = 254\n",
        "\n",
        "                  nr = [ptc % 12]\n",
        "                  if nr in wk:\n",
        "                    color = 0     \n",
        "                  else:\n",
        "                    color = 128\n",
        "\n",
        "                if events_matrix1[i][1] >= pe[1] and events_matrix1[i+1][1] == events_matrix1[i][1]:\n",
        "                  # noc = 255 # Chord\n",
        "                  # ptc+0 - White Chord Note\n",
        "                  # ptc+128 - Black Chord Note\n",
        "\n",
        "                  noc = 255\n",
        "\n",
        "                  cr = [ptc % 12]\n",
        "                  if cr in wk:\n",
        "                    color = 0     \n",
        "                  else:\n",
        "                    color = 128\n",
        "                \n",
        "                if events_matrix1[i][1] == pe[1] and events_matrix1[i+1][1] != events_matrix1[i][1]:\n",
        "                  # noc = 255 # Chord\n",
        "                  # ptc+0 - White Chord Note\n",
        "                  # ptc+128 - Black Chord Note\n",
        "\n",
        "                  noc = 255\n",
        "\n",
        "                  cr = [ptc % 12]\n",
        "                  if cr in wk:\n",
        "                    color = 0     \n",
        "                  else:\n",
        "                    color = 128\n",
        "\n",
        "                melody_chords.append([noc, time, dur, ptc+color])\n",
        "\n",
        "                # Stats\n",
        "\n",
        "                nocs.append(noc)\n",
        "                times.append(time)\n",
        "                durs.append(dur)\n",
        "                pitches.append(ptc)\n",
        "\n",
        "                pe = events_matrix1[i]\n",
        "\n",
        "            melody_chords_f.append(melody_chords)\n",
        "\n",
        "        gfiles.append(f)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "        \n",
        "print('=' * 70)\n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "print('Saving...')\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, full_path_to_save_processed_MIDIs)\n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "# Dataset stats...\n",
        "print('Generating dataset stats...')\n",
        "\n",
        "tavg = sum(times) / len(times)\n",
        "davg = sum(durs) / len(durs)\n",
        "pavg = sum(pitches) / len(pitches)\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Single notes count', nocs.count(254))\n",
        "print('Chords notes count', nocs.count(255))\n",
        "print('Average time-shift', tavg)\n",
        "print('Average duration', davg)\n",
        "print('Average pitch', pavg)\n",
        "print('Done!')   \n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PROCESS)"
      ],
      "metadata": {
        "id": "5X0WPlVWj8tC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0826f622-2edc-4f09-9a01-58df049738d4",
          "kernelId": ""
        },
        "id": "t-jV34sBHX9z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Process and prep INTs...\n",
        "randomize_dataset = True #@param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping INTs dataset...')\n",
        "\n",
        "if randomize_dataset:\n",
        "    print('=' * 70)\n",
        "    print('Randomizing the dataset...')\n",
        "    random.shuffle(melody_chords_f)\n",
        "    print('Done!')\n",
        "    \n",
        "print('=' * 70)\n",
        "print('Processing the dataset...')\n",
        "\n",
        "train_data1 = []\n",
        "\n",
        "for chords_list in tqdm(melody_chords_f):\n",
        "    for i in chords_list:\n",
        "      \n",
        "      train_data1.extend([i[0], i[1], i[2], i[3]]) # [noc, time, dur, ptc]\n",
        "\n",
        "print('Done!')        \n",
        "print('=' * 70)\n",
        "        \n",
        "print('Total INTs:', len(train_data1))\n",
        "print('Minimum INT:', min(train_data1))\n",
        "print('Maximum INT:', max(train_data1))\n",
        "print('Unique INTs:', len(set(train_data1)))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save INTs\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(train_data1, '/content/DeBussy_INTS')"
      ],
      "metadata": {
        "id": "P29hQViyaoKQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "execution_count": 6,
          "id": "dd411e56-532f-47dd-8283-ecb57126a3ae",
          "kernelId": ""
        },
        "id": "p14gn48SHX90",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Test the resulting INTs dataset...\n",
        "\n",
        "print('Sample INTs:', train_data1[:15])\n",
        "\n",
        "out = train_data1[:1600]\n",
        "\n",
        "if len(out) != 0:\n",
        "    \n",
        "    song = out\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "    son = [254]\n",
        "    for s in song[1:]:\n",
        "\n",
        "        if s < 254:\n",
        "          son.append(s)\n",
        "\n",
        "        else:\n",
        "            time += son[0]\n",
        "\n",
        "            dur = ((son[1]) * 2) + 2\n",
        "            \n",
        "            channel = 0 # Piano\n",
        "\n",
        "            if son[2] // 128 != 0:\n",
        "              pitch = son[2]-128\n",
        "            else:\n",
        "              pitch = son[2]\n",
        "            \n",
        "            # Velocities for notes and chords:\n",
        "            if s == 254:\n",
        "              vel = son[2] # Note velocity == note pitch value\n",
        "\n",
        "            else:\n",
        "              vel = son[2] + 20 # Chord velocity == chord pitch values + 20\n",
        "                               \n",
        "            song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "            \n",
        "            son = []\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'DeBussy',  \n",
        "                                                        output_file_name = '/content/DeBussy-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')\n",
        "\n",
        "print('Displaying resulting composition...')\n",
        "fname = '/content/DeBussy-Music-Composition'\n",
        "\n",
        "pm = pretty_midi.PrettyMIDI(fname + '.mid')\n",
        "\n",
        "# Retrieve piano roll of the MIDI file\n",
        "piano_roll = pm.get_piano_roll()\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.specshow(piano_roll, x_axis='time', y_axis='cqt_note', fmin=1, hop_length=160, sr=16000, cmap=plt.cm.hot)\n",
        "plt.title(fname)\n",
        "\n",
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "Audio(str(fname + '.wav'), rate=16000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVqviDzJOrv"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load processed INTs dataset\n",
        "\n",
        "SEQ_LEN = max_seq\n",
        "\n",
        "BATCH_SIZE = 16 # Change this to your specs\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "data_train, data_val = torch.LongTensor(train_data1[:-(SEQ_LEN * BATCH_SIZE)]), torch.LongTensor(train_data1[-(SEQ_LEN * BATCH_SIZE)-1:])\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand = random.randint(0, (self.data.size(0)-self.seq_len) // self.seq_len) * self.seq_len\n",
        "        x = self.data[rand: rand + self.seq_len].long()\n",
        "        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n",
        "        return x, trg\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n",
        "\n",
        "train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "print('Total INTs in the dataset', len(train_data1))\n",
        "print('Total unique INTs in the dataset', len(set(train_data1)))\n",
        "print('Max INT in the dataset', max(train_data1))\n",
        "print('Min INT in the dataset', min(train_data1))\n",
        "print('=' * 50)\n",
        "\n",
        "print('Length of the dataset:',len(train_dataset))\n",
        "print('Number of dataset samples:', (len(train_dataset) // SEQ_LEN))\n",
        "print('Length of data loader',len(train_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "id": "_KoJ-hwP5iU2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
          "kernelId": ""
        },
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "\n",
        "DIC_SIZE = 256\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=512,\n",
        "                   n_layer=8, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model) # Multi-GPU training...\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
          "kernelId": ""
        },
        "id": "R4LIXk1vHX92",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Eval funct to eval separately if needed\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# (MODEL SAVE/LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
          "kernelId": ""
        },
        "id": "gqyDatHC9X1z"
      },
      "outputs": [],
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/DeBussy-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load/Reload the model\n",
        "\n",
        "full_path_to_model_checkpoint = \"/content/DeBussy-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "\n",
        "print('Loading the model...')\n",
        "config = GPTConfig(256, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=512,\n",
        "                   n_layer=8, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "state_dict = torch.load(full_path_to_model_checkpoint, map_location=device)\n",
        "\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    name = k[7:] #remove 'module'\n",
        "    new_state_dict[name] = v\n",
        "\n",
        "model.load_state_dict(new_state_dict)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-NLe35B0b9a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (GENERATE)"
      ],
      "metadata": {
        "id": "RCKJSbl4erb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom MIDI option\n",
        "full_path_to_custom_MIDI = \"/content/tegridy-tools/tegridy-tools/seed2.mid\" #@param {type:\"string\"}\n",
        "\n",
        "print('Loading custom MIDI file...')\n",
        "\n",
        "score = TMIDIX.midi2ms_score(open(full_path_to_custom_MIDI, 'rb').read())\n",
        "\n",
        "events_matrix1 = []\n",
        "\n",
        "itrack = 1\n",
        "\n",
        "while itrack < len(score):\n",
        "    for event in score[itrack]:         \n",
        "        if event[0] == 'note' and event[3] != 9:\n",
        "            events_matrix1.append(event)\n",
        "    itrack += 1\n",
        "\n",
        "# final processing...\n",
        "\n",
        "if len(events_matrix1) > 0:\n",
        "\n",
        "    # recalculating timings\n",
        "\n",
        "    for e in events_matrix1:\n",
        "        # e[1] = int(e[1] / 5)\n",
        "        e[2] = int(e[2] / 2)\n",
        "\n",
        "    events_matrix1.sort(key=lambda x: x[4], reverse=True) # Sort by pitch H -> L\n",
        "    events_matrix1.sort(key=lambda x: x[1]) # Then sort by start-times\n",
        "    \n",
        "    noc = 254 # Note or Chord\n",
        "    color = 0\n",
        "\n",
        "    melody_chords = []\n",
        "    \n",
        "    pe = events_matrix1[0]\n",
        "\n",
        "    for i in range(len(events_matrix1)-1):\n",
        "\n",
        "        time = max(0, min(253, events_matrix1[i][1]-pe[1])) # Time-shift\n",
        "        dur = max(0, min(253, events_matrix1[i][2])) # Duration\n",
        "        ptc = max(0, min(127, events_matrix1[i][4])) # Pitch\n",
        "\n",
        "        if events_matrix1[i][1] > pe[1] and events_matrix1[i+1][1] != events_matrix1[i][1]:\n",
        "          # noc = 254 # Single Note\n",
        "          # ptc+0 - White Note\n",
        "          # ptc+128 - Black Note\n",
        "\n",
        "          noc = 254\n",
        "\n",
        "          nr = [ptc % 12]\n",
        "          if nr in wk:\n",
        "            color = 0     \n",
        "          else:\n",
        "            color = 128\n",
        "\n",
        "        if events_matrix1[i][1] >= pe[1] and events_matrix1[i+1][1] == events_matrix1[i][1]:\n",
        "          # noc = 255 # Chord\n",
        "          # ptc+0 - White Chord Note\n",
        "          # ptc+128 - Black Chord Note\n",
        "\n",
        "          noc = 255\n",
        "\n",
        "          cr = [ptc % 12]\n",
        "          if cr in wk:\n",
        "            color = 0     \n",
        "          else:\n",
        "            color = 128\n",
        "        \n",
        "        if events_matrix1[i][1] == pe[1] and events_matrix1[i+1][1] != events_matrix1[i][1]:\n",
        "          # noc = 255 # Chord\n",
        "          # ptc+0 - White Chord Note\n",
        "          # ptc+128 - Black Chord Note\n",
        "\n",
        "          noc = 255\n",
        "\n",
        "          cr = [ptc % 12]\n",
        "          if cr in wk:\n",
        "            color = 0     \n",
        "          else:\n",
        "            color = 128\n",
        "\n",
        "        melody_chords.append([noc, time, dur, ptc+color])\n",
        "\n",
        "        pe = events_matrix1[i]\n",
        "\n",
        "inputs = []\n",
        "\n",
        "for i in melody_chords:\n",
        "  \n",
        "      inputs.extend([i[0], i[1], i[2], i[3]]) # [noc, time, dur, ptc]\n",
        "\n",
        "print('Done!')        "
      ],
      "metadata": {
        "cellView": "form",
        "id": "zpNJ3mPO_xlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate music\n",
        "\n",
        "#@markdown NOTE: Play with the settings to get different results\n",
        "\n",
        "priming_type = \"Random Dataset Point\" #@param [\"Random Dataset Point\", \"Custom MIDI\"]\n",
        "freeze_priming_point = False #@param {type:\"boolean\"}\n",
        "number_of_prime_tokens = 256 #@param {type:\"slider\", min:64, max:512, step:16}\n",
        "number_of_tokens_to_generate = 128 #@param {type:\"slider\", min:64, max:512, step:16}\n",
        "number_of_continuation_blocks = 32 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "show_stats = False #@param {type:\"boolean\"}\n",
        "\n",
        "#===================================================================\n",
        "print('=' * 70)\n",
        "print('DeBussy Music Model Continuation Generator')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Generation settings:')\n",
        "print('=' * 70)\n",
        "print('Priming type:', priming_type)\n",
        "print('Number of prime tokens:', number_of_prime_tokens)\n",
        "print('Number of tokens:', number_of_tokens_to_generate)\n",
        "print('Number of continuation blocks:', number_of_continuation_blocks)\n",
        "print('Model temperature:', temperature)\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping...')\n",
        "\n",
        "out = []\n",
        "out1 = []\n",
        "\n",
        "if not freeze_priming_point:\n",
        "  r = random.randint(0, len(train_data1))\n",
        "\n",
        "out = train_data1[r:r+(number_of_prime_tokens*2)]\n",
        "out1.extend(out)\n",
        "\n",
        "if priming_type == 'Custom MIDI':\n",
        "  out = []\n",
        "  out1 = []\n",
        "  out = inputs\n",
        "  out1.extend(out[:number_of_prime_tokens])\n",
        "\n",
        "tokens_range = 256\n",
        "\n",
        "print('=' * 70)\n",
        "print('Generating...')\n",
        "\n",
        "for i in range(number_of_continuation_blocks):\n",
        "\n",
        "  if show_stats: \n",
        "    print('=' * 70)\n",
        "    print('Block #', i)\n",
        "\n",
        "  rand_seq = model.generate(torch.Tensor(out[-number_of_prime_tokens:]), \n",
        "                                          target_seq_length=number_of_tokens_to_generate+number_of_prime_tokens,\n",
        "                                          temperature=temperature,\n",
        "                                          stop_token=tokens_range,\n",
        "                                          verbose=show_stats)\n",
        "  \n",
        "  out = rand_seq[0].cpu().numpy().tolist()\n",
        "  \n",
        "  out1.extend(out[number_of_prime_tokens:])\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "\n",
        "if show_stats:\n",
        "  print('=' * 70)\n",
        "  print('Detokenizing output...')\n",
        "\n",
        "if len(out1) != 0:\n",
        "    \n",
        "    song = out1\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "    son = [254]\n",
        "    for s in song[1:]:\n",
        "\n",
        "        if s < 254:\n",
        "          son.append(s)\n",
        "\n",
        "        else:\n",
        "          if len(son) == 3:\n",
        "\n",
        "            time += son[0]\n",
        "\n",
        "            dur = ((son[1]) * 2) + 2\n",
        "            \n",
        "            channel = 0 # Piano\n",
        "\n",
        "            if son[2] // 128 != 0:\n",
        "              pitch = son[2]-128\n",
        "            else:\n",
        "              pitch = son[2]\n",
        "            \n",
        "            # Velocities for notes and chords:\n",
        "            if s == 254:\n",
        "              vel = son[2] # Note velocity == note pitch value\n",
        "\n",
        "            else:\n",
        "              vel = son[2] + 20 # Chord velocity == chord pitch values + 20\n",
        "                               \n",
        "            song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "            \n",
        "          son = []\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'DeBussy',  \n",
        "                                                        output_file_name = '/content/DeBussy-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')\n",
        "\n",
        "else:\n",
        "  print('Models output is empty! Check the code...')\n",
        "  print('Shutting down...')\n",
        "\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "print('Displaying resulting composition...')\n",
        "fname = '/content/DeBussy-Music-Composition'\n",
        "\n",
        "pm = pretty_midi.PrettyMIDI(fname + '.mid')\n",
        "\n",
        "# Retrieve piano roll of the MIDI file\n",
        "piano_roll = pm.get_piano_roll()\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.specshow(piano_roll, x_axis='time', y_axis='cqt_note', fmin=1, hop_length=160, sr=16000, cmap=plt.cm.hot)\n",
        "plt.title(fname)\n",
        "\n",
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "Audio(str(fname + '.wav'), rate=16000)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H_20oe1GcIIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeBussy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}